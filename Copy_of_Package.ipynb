{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# My package"
      ],
      "metadata": {
        "id": "0Car1IZNZJmh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgM5WXSjXx5E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing functions"
      ],
      "metadata": {
        "id": "b_ZP3aAeTpf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(data):\n",
        "    '''Dynamic_Payment_Segment'''\n",
        "    new_dynamic = {'0) NonPayer': 0, '1) ExPayer': 1, '2) Minnow': 2, '3) Dolphin': 3, '4) Whale': 4}\n",
        "    data['dynamic_payment_segment'] = data['dynamic_payment_segment'].map(new_dynamic)\n",
        "\n",
        "    '''Global_Competition_Level'''\n",
        "    data['global_competition_level'].fillna(0, inplace = True)\n",
        "\n",
        "    '''Season'''\n",
        "    data.drop('season', axis = 1, inplace=True)\n",
        "    return data"
      ],
      "metadata": {
        "id": "13RNwBIdednH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_preprocessing(data):\n",
        "    data = preprocessing(data)\n",
        "    '''registration country'''\n",
        "    data = data.drop('registration_country', axis=1)\n",
        "\n",
        "    '''registration platform'''\n",
        "    data = data.drop('registration_platform_specific', axis=1)\n",
        "    return data"
      ],
      "metadata": {
        "id": "bVnJEFdyTupY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def heavy_preprocessing(data):\n",
        "    data = preprocessing(data)\n",
        "    '''registration country'''\n",
        "    top_20_countries = [x for x in data.registration_country.value_counts().head(20).index]\n",
        "    for label in top_20_countries:\n",
        "        data[label] = np.where(data['registration_country'] == label, 1, 0)\n",
        "    data = data.drop('registration_country', axis=1)\n",
        "\n",
        "    '''registration platform'''\n",
        "    platforms = list(data['registration_platform_specific'].unique())[:10]\n",
        "    for label in platforms:\n",
        "        data[label] = np.where(data['registration_platform_specific'] == label, 1, 0)\n",
        "    data = data.drop('registration_platform_specific', axis=1)\n",
        "    return data"
      ],
      "metadata": {
        "id": "yUBHh3KZpl3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection"
      ],
      "metadata": {
        "id": "2tBr-o8aTz6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Feature_Selection(data):\n",
        "    data = data.drop('avg_stars_top_14_players', axis = 1)\n",
        "    data = data.drop('cohort_season', axis = 1)\n",
        "    return data\n",
        "def Radical_Feature_Selection(data):\n",
        "    data = Feature_Selection(data)\n",
        "    data = data.drop('tokens_stash', axis = 1)\n",
        "    data = data.drop('rests_stash', axis = 1)\n",
        "    return data\n",
        "def Super_Radical_Feature_Selection(data):\n",
        "    data = Feature_Selection(data)\n",
        "    data = data.drop('dynamic_payment_segment', axis = 1)\n",
        "    data = data.drop('league_match_watched_count_last_28_days', axis = 1)\n",
        "    return data"
      ],
      "metadata": {
        "id": "QDEHYm8EvC-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature ingineering"
      ],
      "metadata": {
        "id": "n0YKyUEVT4XR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Averaging_by_leagues(data):\n",
        "    list_of_features = data.columns.tolist()\n",
        "    list_of_features.remove('league_rank')\n",
        "    list_of_features.remove('league_id')\n",
        "    for feature in list_of_features:\n",
        "        updated_feature = data.groupby('league_id')[feature].transform('mean')\n",
        "        data['averaged_' + feature] = data[feature] / updated_feature\n",
        "        data['averaged_' + feature].fillna(0, inplace = True)\n",
        "        data = data.drop(feature, axis = 1)\n",
        "    return data"
      ],
      "metadata": {
        "id": "2wPVyW8mdi1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train test val split"
      ],
      "metadata": {
        "id": "DCD3v8RYT_AK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test_split_adapted_shuffled(data):\n",
        "    list_of_choices = np.random.choice([0,1,2], size = int(data.shape[0] / 14), p = [0.7, 0.15, 0.15])\n",
        "    permutation = np.arange(int(data.shape[0] / 14))\n",
        "    np.random.shuffle(permutation)\n",
        "\n",
        "\n",
        "    index_league_rank = data.columns.get_loc('league_rank')\n",
        "    X = data.iloc[:,:].values\n",
        "    train_set, val_set, test_set = [], [], []\n",
        "\n",
        "    for p in permutation:\n",
        "        if list_of_choices[p] == 0:\n",
        "                train_set.append(X[14*p:(p+1)*14, :])\n",
        "        elif list_of_choices[p] == 1:\n",
        "                val_set.append(X[14*p:(p+1)*14, :])\n",
        "        else:\n",
        "                test_set.append(X[14*p:(p+1)*14, :])\n",
        "\n",
        "    train_set, val_set, test_set = np.concatenate(train_set), np.concatenate(val_set), np.concatenate(test_set)\n",
        "\n",
        "    return (np.concatenate((train_set[:, :index_league_rank], train_set[:, index_league_rank+1:]), axis=1),\n",
        "            train_set[:, index_league_rank],\n",
        "            np.concatenate((val_set[:, :index_league_rank], val_set[:, index_league_rank+1:]), axis=1),\n",
        "            val_set[:, index_league_rank],\n",
        "            np.concatenate((test_set[:, :index_league_rank], test_set[:, index_league_rank+1:]), axis=1),\n",
        "            test_set[:, index_league_rank]\n",
        "            )\n",
        "#X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split_adapted(dataset)"
      ],
      "metadata": {
        "id": "qv3l3iZPbJUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Postprocessing functions"
      ],
      "metadata": {
        "id": "3eKQJ85TUCLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "def post_processing(y_pred):\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i] < 1: y_pred[i] = 1\n",
        "        elif y_pred[i] > 14: y_pred[i] = 14\n",
        "        else: y_pred[i] = np.round(y_pred[i])"
      ],
      "metadata": {
        "id": "w1DeVAKtvM-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post_processing_1(y):\n",
        "    y_pred = copy.deepcopy(y)\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i] < 1: y_pred[i] = 1\n",
        "        elif y_pred[i] > 14: y_pred[i] = 14\n",
        "        else: y_pred[i] = np.round(y_pred[i])\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "jxtq1s2GZSC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_post_process(y_p):\n",
        "    y_p_copy = y_p[:]\n",
        "    temp = np.argsort(np.array(y_p))\n",
        "    for i in range(len(y_p)):\n",
        "        y_p_copy[temp[i]] = i + 1\n",
        "    return y_p_copy\n",
        "\n",
        "def post_sorting(y_pred, length):\n",
        "    y_prediction = copy.deepcopy(y_pred)\n",
        "    n = int(len(y_prediction) / length)\n",
        "\n",
        "    for i in range(n):\n",
        "        y_prediction[i*length:(i+1)*length] = one_post_process(y_prediction[i*length:(i+1)*length])\n",
        "\n",
        "    return y_prediction"
      ],
      "metadata": {
        "id": "5kwkSBGjwaCS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}